{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36388f5",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries.\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ebooklib import epub\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from lingua import Language, LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d04b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06c1dc",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed217f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "directory = 'data' \n",
    "file_name = 'Hesse, Herman - Siddhartha, eine indische Dichting.epub'\n",
    "file_path = os.path.join('data', file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03b467",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the book.\n",
    "book = epub.read_epub(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fb618",
   "metadata": {},
   "source": [
    "## Create a list of all the unique words in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749eaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unique_words_list(book):\n",
    "    # Variable in which the raw text of the book will be stored.\n",
    "    text = ''\n",
    "    \n",
    "    # Loop through book items.\n",
    "    for item in book.get_items():\n",
    "        if isinstance(item, epub.EpubHtml): # Get all EpubHTML items out of the book. \n",
    "            text += item.get_content().decode('utf-8') # Add it to the text variable.\n",
    "\n",
    "    # Clean the text of HTML related element.\n",
    "    cleaned_text = re.sub('<.*?>', '', text)\n",
    "    \n",
    "    # Remove all punctuation marks.\n",
    "    cleaned_text = cleaned_text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Turn it into a list.\n",
    "    word_list = cleaned_text.split()\n",
    "    print(f'The book contains {len(word_list)} words.')\n",
    "    \n",
    "    # Get unique words.\n",
    "    unique_words = list(set(word_list))\n",
    "    print(f'There are {len(unique_words)} unique words.')\n",
    "    \n",
    "    return word_list, unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba1d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, unique_words = create_unique_words_list(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837d21d",
   "metadata": {},
   "source": [
    "## Delete words that are not German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbccb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_languages(word_list):\n",
    "    # Possible languages that are present in the book.\n",
    "    languages = [Language.ENGLISH, Language.GERMAN]\n",
    "    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "    german_words = []\n",
    "    \n",
    "    # Loop through all words.\n",
    "    for word in word_list:\n",
    "        # Obtain confidence intervals.\n",
    "        confidence_values = detector.compute_language_confidence_values(word)\n",
    "        \n",
    "        # Loop through confidence intervals.\n",
    "        for language, value in confidence_values:\n",
    "            if language.name == 'GERMAN' and value >= 0.5: # Statement should be adjusted if there are more than 2\n",
    "                # languages present in the book, but this is unlikely.\n",
    "                german_words.append(word)\n",
    "        \n",
    "    print(f'There were {len(word_list)} unique words present in the book.')\n",
    "    print(f'After language detection, there are {len(german_words)} German words left.')\n",
    "    \n",
    "    return german_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36113485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take some time.\n",
    "unique_words = detect_languages(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c73d",
   "metadata": {},
   "source": [
    "## Print the most occuring words in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15123e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_common_words(word_list, number_of_elements):\n",
    "    # Use the Counter method to count the occurrences of each word in the word_list\n",
    "    word_counts = Counter(word_list)\n",
    "\n",
    "    # Get the number_of_elements most common words from the word_counts\n",
    "    most_common_words = word_counts.most_common(number_of_elements)\n",
    "\n",
    "    # Print the header for the output\n",
    "    print(f'The top {number_of_elements} most occurent words are:\\n')\n",
    "\n",
    "    # Loop through the most_common_words and print each word and its count\n",
    "    for word, count in most_common_words:\n",
    "        print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e4f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_most_common_words(word_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2267f81e",
   "metadata": {},
   "source": [
    "## Categorize all the words into nouns, verbs, adjectives etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_words(unique_words):\n",
    "    # Use nltk to categorize each word in the list\n",
    "    tagged_words = nltk.pos_tag(unique_words)\n",
    "    \n",
    "    # Convert the tagged words into a pandas dataframe\n",
    "    df = pd.DataFrame(tagged_words, columns=['word', 'type'])\n",
    "    \n",
    "    # Sort the dataframe first by the type of word and then alphabetically by the word\n",
    "    df = df.sort_values(by=['type', 'word'], ascending=[False, True])\n",
    "    \n",
    "    # Reset the index of the dataframe\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Return both the tagged words and the sorted dataframe\n",
    "    return tagged_words, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be13789",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words, df = categorize_words(unique_words)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fd455",
   "metadata": {},
   "source": [
    "## Print how much words there are in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_words_in_category(tagged_words):\n",
    "    # Create an empty dictionary to store the frequency count of each category\n",
    "    frequency_count = {}\n",
    "\n",
    "    # Loop through each word and its category in tagged_words\n",
    "    for _, value in tagged_words:\n",
    "        # Check if the category is already present in the frequency_count dictionary\n",
    "        if value in frequency_count:\n",
    "            # If yes, increment its count by 1\n",
    "            frequency_count[value] += 1\n",
    "        else:\n",
    "            # If not, add the category to the dictionary with a count of 1\n",
    "            frequency_count[value] = 1\n",
    "            \n",
    "    # Sort the frequency_count dictionary in descending order based on the count of each category\n",
    "    frequency_count = {k: v for k, v in sorted(frequency_count.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    # Print the total number of unique words in the book and the count of each category\n",
    "    print(f'In total there are {len(tagged_words)} unique words present in the book. Of these there are: \\n')\n",
    "    for i,j in frequency_count.items():\n",
    "        print(i,j)\n",
    "        \n",
    "    return frequency_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_count = number_of_words_in_category(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b956e1",
   "metadata": {},
   "source": [
    "## Print category meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4513476",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_ in frequency_count.items():\n",
    "    nltk.help.upenn_tagset(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad953f3c",
   "metadata": {},
   "source": [
    "## Translate the German words into Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain German nouns \n",
    "german_nouns = df[df.type == 'NNP'].reset_index(drop=True)\n",
    "german_nouns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_words(df, source_language='de', target_language='nl'):\n",
    "    # Initialize an empty list to store the translated words\n",
    "    translated_words = []\n",
    "      \n",
    "    # Loop through each word in the 'word' column of the input DataFrame, using tqdm to display a progress bar\n",
    "    for word in tqdm(df['word'], desc='Translating words'):\n",
    "        # Create a TextBlob object from the current word\n",
    "        blob = TextBlob(word)\n",
    "        \n",
    "        # Attempt to translate the word from the source language to the target language\n",
    "        try:\n",
    "            translated_word = blob.translate(from_lang=source_language, to=target_language)\n",
    "        except:\n",
    "            # If the translation fails, assign an empty string to the translated word\n",
    "            translated_word = ''\n",
    "        \n",
    "        # Convert the translated word to a string and add it to the list of translated words\n",
    "        translated_words.append(str(translated_word))\n",
    "      \n",
    "    # Add a new column to the input DataFrame containing the translated words, and reset the index of the DataFrame\n",
    "    return df.assign(translation=translated_words).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81006269",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = translate_words(german_nouns)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('hesse.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
