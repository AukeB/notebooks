{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f259a78a-ff67-4584-84fc-1cfc705ef368",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9462773-03a8-4614-ab84-0bd14df57a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pytube\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80806c-e037-4a7f-bdd9-cb02ef844976",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7f05f-43e2-49a9-8f6d-9596d35bc1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_audio(url: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads the audio of a YouTube video.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the YouTube video.\n",
    "        output_path (str): The path to save the downloaded audio file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creating a YouTube object\n",
    "        yt = YouTube(url)\n",
    "\n",
    "        # Extracting audio stream\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "\n",
    "        # Downloading audio\n",
    "        audio_stream.download(output_path=output_path)\n",
    "        print(\"Audio downloaded successfully.\")\n",
    "    except (pytube.exceptions.RegexMatchError, pytube.exceptions.VideoUnavailable) as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "def split_string_into_chunks(text: str, chunk_size: int = 2000) -> list:\n",
    "    \"\"\"\n",
    "    Splits a string into chunks of approximately equal size,\n",
    "    ensuring that words are not split.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string to split.\n",
    "        chunk_size (int): The approximate size of each chunk. Default is 2000.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings where each element holds approximately 2000 characters.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    words = text.split()  # Split text into words\n",
    "\n",
    "    for word in words:\n",
    "        # Check if adding the next word would exceed the chunk size\n",
    "        if len(current_chunk) + len(word) + 1 <= chunk_size:  # Adding 1 for space\n",
    "            current_chunk += word + \" \"\n",
    "        else:\n",
    "            chunks.append(current_chunk[:-1])  # Remove the trailing space\n",
    "            current_chunk = word + \" \"\n",
    "\n",
    "    # Add the remaining chunk if any\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk[:-1])  # Remove the trailing space\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def merge_text_with_timestamp(data: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Merge text with corresponding timestamps into a single string.\n",
    "\n",
    "    Args:\n",
    "        data (List[Dict[str, str]]): A list of dictionaries containing 'start' key specifying start time\n",
    "            and 'text' key containing a sentence.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string where each sentence is preceded by its corresponding timestamp in the format \"m:ss.s\".\n",
    "\n",
    "    Example:\n",
    "        data = [\n",
    "            {'start': '0.00', 'text': 'This is the first sentence.'},\n",
    "            {'start': '1.23', 'text': 'This is the second sentence.'},\n",
    "            {'start': '3.45', 'text': 'This is the third sentence.'}\n",
    "        ]\n",
    "        merged_text = merge_text_with_timestamp(data)\n",
    "        print(merged_text)\n",
    "        # Output:\n",
    "        # [0:00.0] This is the first sentence. [0:01.2] This is the second sentence. [0:03.5] This is the third sentence.\n",
    "    \"\"\"\n",
    "    merged_text = \"\"\n",
    "    for entry in data:\n",
    "        timestamp = float(entry['start'])\n",
    "        minutes = int(timestamp / 60)\n",
    "        seconds = timestamp % 60\n",
    "        formatted_timestamp = f\"[{minutes}m{seconds:.1f}s] \"\n",
    "        merged_text += formatted_timestamp + entry['text'] + \" \"\n",
    "    merged_text = ' '.join(merged_text.split())\n",
    "    \n",
    "    return merged_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c165ccf-286e-4a03-8d6a-8ae6b69ecee2",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7c02-caf0-47c6-8efe-68260730fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63365288-c319-4607-ac57-e79a4510a4b7",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe573cc9-4e27-4f31-b4cf-7e2237f758f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download audio file from youtube.\n",
    "url = \"https://www.youtube.com/watch?v=gS9PWbQuKsU\"\n",
    "output_path = \"change/this/path\"\n",
    "output_path = output_path.replace(\"\\\\\", \"/\")\n",
    "                                  \n",
    "# download_youtube_audio(\n",
    "#     url=url,\n",
    "#     output_path=output_path\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55937f7c-ba57-4e9a-b438-c2b88da7662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the audio file\n",
    "audio_file_name = \"interview.aac\"\n",
    "audio_file_path = f\"{output_path}/{audio_file_name}\"\n",
    "result = model.transcribe(audio_file_path, language=\"dutch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6486038f-5445-41c8-979c-32c40d444628",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d77251-5cdb-49b7-ad4d-163a37c2c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_with_all_timestamps = merge_text_with_timestamp(result['segments'])\n",
    "for char in transcript_with_all_timestamps:\n",
    "    if char == \"[\":\n",
    "        print('')\n",
    "    print(char, end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff745b1-d70e-4a7c-a57e-bd8034c43d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to chunks.\n",
    "transcript_chunks = split_string_into_chunks(transcript_with_all_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ce93a-a408-44d9-8880-7276dd8e4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display chunks.\n",
    "i = 0\n",
    "for chunk in transcript_chunks:\n",
    "    print(i)\n",
    "    print(chunk)\n",
    "    print(\"\\n\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
